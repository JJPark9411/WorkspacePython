{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'konlpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4edf7443ba0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKomoran\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKomoran\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 형태소 분석기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquote_plus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'konlpy'"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran\n",
    "tagger = Komoran()  # 형태소 분석기\n",
    "from urllib.parse import quote_plus\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import lxml.html\n",
    "import codecs\n",
    "\n",
    "# 투캅스 시나리오 읽어오기\n",
    "# http://www.korean.go.kr(국립국어원)에서 회원가입 후 다운로드\n",
    "articles = []\n",
    "fp = codecs.open(\"투캅스(배포불가).txt\", \"r\", encoding=\"utf-8\")\n",
    "soup = BeautifulSoup(fp, \"html.parser\")\n",
    "body = soup.select_one(\"body\")\n",
    "text = body.getText()\n",
    "articles = text.split(\"\\n\")\n",
    "len(articles)\n",
    "fp.close()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#명사만 추출\n",
    "def get_noun(text):\n",
    "    nouns = tagger.nouns(text)\n",
    "    return [n for n in nouns if len(n) > 1]  # 2글자 이상인 명사만 추출\n",
    "\n",
    "#TF-IDF 행렬구하기\n",
    "cv = TfidfVectorizer(tokenizer=get_noun, max_features=100)\n",
    "tdm = cv.fit_transform(articles)\n",
    "\n",
    "#print(tdm.toarray())\n",
    "#print(tdm) \n",
    "\n",
    "import numpy\n",
    "import operator\n",
    "words = cv.get_feature_names()\n",
    "count_mat = tdm.sum(axis=0)\n",
    "count = numpy.squeeze(numpy.asarray(count_mat))\n",
    "word_count = list(zip(words, count))\n",
    "word_count = sorted(word_count, key=operator.itemgetter(1), reverse=True)\n",
    "word_count\n",
    "\n",
    "hot_key = list(dict(word_count[:50]).keys())\n",
    "hot_key\n",
    "\n",
    "#word cloud\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot\n",
    "from wordcloud import WordCloud\n",
    "wc = WordCloud(font_path='C:\\\\Windows\\\\Fonts\\\\NGULIM.ttf', background_color='white', width=400, height=300)\n",
    "cloud = wc.fit_words(dict(word_count))\n",
    "pyplot.figure(figsize=(12, 9))\n",
    "pyplot.imshow(cloud)\n",
    "pyplot.axis(\"off\")\n",
    "pyplot.show()\n",
    "\n",
    "#형태소 분석기 라이브러리 로딩\n",
    "import codecs\n",
    "from konlpy.tag import Twitter\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 텍스트를 처리하기\n",
    "twitter = Twitter()\n",
    "results = []\n",
    "lines = articles\n",
    "words_all = []\n",
    "\n",
    "for line in lines:\n",
    "    # 형태소 분석하기\n",
    "    malist = twitter.pos(line, norm=True, stem=True)\n",
    "    r = []\n",
    "    for word in malist:\n",
    "        # 명사/동사/부사만 걸러내기 \n",
    "        if word[1] in ['Noun','Verb','Adjective']:\n",
    "            r.append(word[0])\n",
    "            words_all.append(word[0])\n",
    "    rl = (\" \".join(r)).strip()\n",
    "    results.append(rl)\n",
    "    #print(rl)\n",
    "    \n",
    "# 파일로 저장하기\n",
    "from gensim.models import word2vec\n",
    "yang_file = 'yang.model'\n",
    "with open(yang_file, 'w', encoding='utf-8') as fp2:\n",
    "    fp2.write(\"\\n\".join(results))\n",
    "    \n",
    "fp2.close() \n",
    "\n",
    "# Word2Vec 모델\n",
    "data = word2vec.LineSentence(yang_file)\n",
    "model = word2vec.Word2Vec(data,size=200, window=10, hs=1, min_count=2, sg=1)\n",
    "model.save(\"yang_w2v.model\")\n",
    "\n",
    "################ 테스트 ##########################################\n",
    "\n",
    "model.most_similar(positive=[\"경찰\"])    #경찰과 가장 가까운 단어는?\n",
    "model.most_similar(positive=[\"여자\"])    #여자와 가장 가까운 단어는?\n",
    "model[\"장갑\"]                            #장갑의 데이터 임베딩\n",
    "model[\"유괴\"]                            #유괴의 데이터 임베딩\n",
    "model.most_similar(positive=[\"경찰\",\"유괴\"] , negative=[\"여자\"])    #경찰 + 유괴 - 여자\n",
    "\n",
    "#차원축소를 위한 라이브러리\n",
    "from IPython.display import Image\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#차원을 줄여주기(그래프를 그려주기 위함) \n",
    "words = list(model.wv.vocab)\n",
    "X = model[model.wv.vocab]\n",
    "pca = PCA(n_components=2)\n",
    "result = pca.fit_transform(X)\n",
    "\n",
    "#word의 군집화 \n",
    "result2 = StandardScaler().fit_transform(result)\n",
    "db = DBSCAN(eps=0.3, min_samples=10).fit(result2)\n",
    "labels = db.labels_\n",
    "\n",
    "import collections\n",
    "import math\n",
    "import numpy as np \n",
    "\n",
    "myCounter = collections.Counter(words_all)\n",
    "#print('myCounter:', myCounter)\n",
    "\n",
    "radiuds = np.array([i for i in list(myCounter.values())])\n",
    "area = np.pi * (radiuds)**2  * 5\n",
    "table_words = list(myCounter.keys()) \n",
    "table_counts = list(list(myCounter.values()))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.font_manager as fm \n",
    "\n",
    "#top50의 단어를 선별하여 word2vec을 계산하고 좌표로 찍어준다. \n",
    "font_location = \"C:\\\\Windows\\\\Fonts\\\\NGULIM.TTF\"\n",
    "font_name = fm.FontProperties(fname=font_location).get_name()\n",
    "matplotlib.rc('font', family=font_name)\n",
    "\n",
    "valid_words = [hot_key[i] for i in range(0,50) if hot_key[i] in words]\n",
    "valid_labels = [words.index(hot_key[i]) for i in range(0,50) if hot_key[i] in words]\n",
    "valid_index = [words.index(str_temp) for str_temp in valid_words]   \n",
    "valid_area = area[[table_words.index(str_temp) for str_temp in valid_words]]   \n",
    "zip_index = zip(valid_index,valid_words)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.scatter(result[valid_index, 0], result[valid_index, 1] , c = valid_labels , s = area , alpha=0.3)\n",
    "for i, word in zip_index:\n",
    "    plt.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1ca4573229a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"경찰\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.most_similar(positive=[\"경찰\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e9e3198c9ed3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"여자\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.most_similar(positive=[\"여자\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[\"장갑\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[\"유괴\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=[\"경찰\",\"유괴\"] , negative=[\"여자\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
